{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce2b10c",
   "metadata": {},
   "source": [
    "## Importing libraries and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e739a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Polygon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# def do_they_intersect\n",
    "def do_they_intersect(x1, y1, r1, x2, y2, r2):\n",
    "    # Distance between both centers\n",
    "    distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    tempBool1 = True\n",
    "    # Do they intersect?\n",
    "    if distance > (r1 + r2) or distance < abs(r1 - r2):\n",
    "        tempBool1 = False\n",
    "       \n",
    "    return tempBool1\n",
    "\n",
    "# def get_intersection_area\n",
    "def get_intersection_area(center1, radius1, center2, radius2):\n",
    "    d = math.dist(center1, center2)  # Distance between centers\n",
    "    # Check if the circles do not overlap\n",
    "    if d >= (radius1 + radius2):\n",
    "        return 0.0\n",
    "    # Check if one circle is completely inside the other\n",
    "    if d <= abs(radius1 - radius2):\n",
    "        return math.pi * min(radius1, radius2)**2\n",
    "    \n",
    "    # Calculate the area of intersection\n",
    "    r1_sq = radius1**2\n",
    "    r2_sq = radius2**2\n",
    "    alpha = math.acos((r1_sq + d**2 - r2_sq) / (2 * radius1 * d)) * 2\n",
    "    beta = math.acos((r2_sq + d**2 - r1_sq) / (2 * radius2 * d)) * 2\n",
    "    segment_area1 = 0.5 * r1_sq * (alpha - math.sin(alpha))\n",
    "    segment_area2 = 0.5 * r2_sq * (beta - math.sin(beta))\n",
    "    intersection_area = segment_area1 + segment_area2\n",
    "    \n",
    "    return intersection_area\n",
    "\n",
    "# def plot2circles\n",
    "def plot_two_circles(center1, radius1, center2, radius2, save_results_to=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    circle1 = plt.Circle(center1, radius1, fill=False, edgecolor='k', linestyle='-', linewidth=1)\n",
    "    circle2 = plt.Circle(center2, radius2, fill=False, edgecolor='r', linestyle='-', linewidth=1)\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "    ax.plot(center1[0], center1[1], 'ko')  # 'bo' is blue color with 'o' marker\n",
    "    ax.plot(center2[0], center2[1], 'ro')  # 'ro' is red color with 'o' marker\n",
    "    ax.plot([center1[0], center2[0]], [center1[1], center2[1]], 'b--')  # 'k--' is black dashed line\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    min_x = min(center1[0] - radius1, center2[0] - radius2)\n",
    "    max_x = max(center1[0] + radius1, center2[0] + radius2)\n",
    "    min_y = min(center1[1] - radius1, center2[1] - radius2)\n",
    "    max_y = max(center1[1] + radius1, center2[1] + radius2)\n",
    "    ax.set_xlim(min_x - 1, max_x + 1)\n",
    "    ax.set_ylim(min_y - 1, max_y + 1)\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.title(\"Particle displacement\")\n",
    "    plt.grid(True)\n",
    "    if save_results_to != None:\n",
    "        plt.savefig(save_results_to, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Defining the main function\n",
    "def get_rock_displacement(location1, location2, radius1, radius2):\n",
    "    # Calculating the distance betweeen both\n",
    "    distance = np.sqrt(np.sum((location1 - location2)**2))\n",
    "    \n",
    "    # Checking intersection\n",
    "    intersect = do_they_intersect(location1[0], location1[1], radius1,\n",
    "                                  location2[0], location2[1], radius2)\n",
    "\n",
    "    # Calculations depending on whether circles intersect or not\n",
    "    if intersect == True:\n",
    "        tempCalc1 = distance + (radius1 + radius2)\n",
    "        maxD = tempCalc1\n",
    "        minD = 0\n",
    "        tempCalc1 = np.pi*radius1**2\n",
    "        tempCalc2 = np.pi*radius2**2\n",
    "        tempCalc3 = get_intersection_area(location1, radius1, location2, radius2)\n",
    "        ratio_minA = tempCalc3/np.min((tempCalc1, tempCalc2))\n",
    "        ratio_maxA = tempCalc3/np.max((tempCalc1, tempCalc2))\n",
    "        intersection_area = tempCalc3\n",
    "    else:\n",
    "        tempCalc1 = distance + (radius1 + radius2)\n",
    "        tempCalc2 = distance - (radius1 + radius2)\n",
    "        maxD = tempCalc1\n",
    "        minD = np.max((tempCalc2, 0))\n",
    "        ratio_minA = 0\n",
    "        ratio_maxA = 0\n",
    "        intersection_area = 0\n",
    "\n",
    "    return distance, intersect, maxD, minD, intersection_area, ratio_minA, ratio_maxA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efea345b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nicol\\\\Documents\\\\GitHub\\\\RFID_tracers\\\\particle_displacement'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2bba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1: 0 duplicate ParticleIDs\n",
      "Dataframe 2: 0 duplicate ParticleIDs\n",
      "Dataframe 3: 0 duplicate ParticleIDs\n",
      "Dataframe 4: 0 duplicate ParticleIDs\n",
      "Dataframe 5: 0 duplicate ParticleIDs\n",
      "Dataframe 6: 0 duplicate ParticleIDs\n",
      "Dataframe 7: 0 duplicate ParticleIDs\n",
      "Dataframe 8: 0 duplicate ParticleIDs\n",
      "Dataframe 9: 0 duplicate ParticleIDs\n"
     ]
    }
   ],
   "source": [
    "# filenames and directories\n",
    "filename1 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_03_28_2022.csv\"\n",
    "filename2 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_07_06_2022.csv\"\n",
    "filename3 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_08_06_2022.csv\"\n",
    "filename4 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_08_09_2022.csv\"\n",
    "filename5 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_08_24_2022.csv\"\n",
    "filename6 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_03_24_2023.csv\"\n",
    "filename7 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_06_17_2023.csv\"\n",
    "filename8 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_07_31_2023.csv\"\n",
    "filename9 = \"../triangulation/triangulated_surveys_code/triangulated_tracer_survey_09_20_2023.csv\"\n",
    "results_directory = \"./results/\"\n",
    "dates = [\"03_28_2022\", \"07_06_2022\", \"08_06_2022\", \"08_09_2022\", \"08_24_22\", \"03_24_2023\", \"06_17_2023\", \"07_31_2023\", \"09_20_2023\"]\n",
    "\n",
    "# reading files\n",
    "dataframe1 = pd.read_csv(filename1)\n",
    "dataframe2 = pd.read_csv(filename2)\n",
    "dataframe3 = pd.read_csv(filename3)\n",
    "dataframe4 = pd.read_csv(filename4)\n",
    "dataframe5 = pd.read_csv(filename5)\n",
    "dataframe6 = pd.read_csv(filename6)\n",
    "dataframe7 = pd.read_csv(filename7)\n",
    "dataframe8 = pd.read_csv(filename8)\n",
    "dataframe9 = pd.read_csv(filename9)\n",
    "\n",
    "# changing the indices\n",
    "dataframe1.index = dataframe1[\"ParticleID\"].astype(np.int64)\n",
    "dataframe2.index = dataframe2[\"ParticleID\"].astype(np.int64)\n",
    "dataframe3.index = dataframe3[\"ParticleID\"].astype(np.int64)\n",
    "dataframe4.index = dataframe4[\"ParticleID\"].astype(np.int64)\n",
    "dataframe5.index = dataframe5[\"ParticleID\"].astype(np.int64)\n",
    "dataframe6.index = dataframe6[\"ParticleID\"].astype(np.int64)\n",
    "dataframe7.index = dataframe7[\"ParticleID\"].astype(np.int64)\n",
    "dataframe8.index = dataframe8[\"ParticleID\"].astype(np.int64)\n",
    "dataframe9.index = dataframe9[\"ParticleID\"].astype(np.int64)\n",
    "\n",
    "# sorting them\n",
    "dataframe1 = dataframe1.sort_index()\n",
    "dataframe2 = dataframe2.sort_index()\n",
    "dataframe3 = dataframe3.sort_index()\n",
    "dataframe4 = dataframe4.sort_index()\n",
    "dataframe5 = dataframe5.sort_index()\n",
    "dataframe6 = dataframe6.sort_index()\n",
    "dataframe7 = dataframe7.sort_index()\n",
    "dataframe8 = dataframe8.sort_index()\n",
    "dataframe9 = dataframe9.sort_index()\n",
    "\n",
    "# Resetting the indices and filling it up\n",
    "full_index = range(0, 1100)\n",
    "\n",
    "dataframe6 = dataframe6.drop_duplicates(subset=\"ParticleID\", keep=\"last\")\n",
    "# checking for duplicates\n",
    "for i, df in enumerate([dataframe1, dataframe2, dataframe3, dataframe4,\n",
    "                        dataframe5, dataframe6, dataframe7, dataframe8, dataframe9], 1):\n",
    "    dup = df[\"ParticleID\"].duplicated().sum()\n",
    "    print(f\"Dataframe {i}: {dup} duplicate ParticleIDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d171cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1 = dataframe1.reindex(full_index)\n",
    "dataframe2 = dataframe2.reindex(full_index)\n",
    "dataframe3 = dataframe3.reindex(full_index)\n",
    "dataframe4 = dataframe4.reindex(full_index)\n",
    "dataframe5 = dataframe5.reindex(full_index)\n",
    "dataframe6 = dataframe6.reindex(full_index)\n",
    "dataframe7 = dataframe7.reindex(full_index)\n",
    "dataframe8 = dataframe8.reindex(full_index)\n",
    "dataframe9 = dataframe9.reindex(full_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d317d",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9054916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data\n",
    "indices = np.array(full_index)\n",
    "\n",
    "location_x = np.column_stack((dataframe1[\"X\"].to_numpy(), \n",
    "                              dataframe2[\"X\"].to_numpy(), \n",
    "                              dataframe3[\"X\"].to_numpy(), \n",
    "                              dataframe4[\"X\"].to_numpy(), \n",
    "                              dataframe5[\"X\"].to_numpy(),\n",
    "                              dataframe6[\"X\"].to_numpy(),\n",
    "                              dataframe7[\"X\"].to_numpy(),\n",
    "                              dataframe8[\"X\"].to_numpy(),\n",
    "                              dataframe9[\"X\"].to_numpy()))\n",
    "\n",
    "location_y = np.column_stack((dataframe1[\"Y\"].to_numpy(), \n",
    "                              dataframe2[\"Y\"].to_numpy(), \n",
    "                              dataframe3[\"Y\"].to_numpy(), \n",
    "                              dataframe4[\"Y\"].to_numpy(), \n",
    "                              dataframe5[\"Y\"].to_numpy(),\n",
    "                              dataframe6[\"Y\"].to_numpy(),\n",
    "                              dataframe7[\"Y\"].to_numpy(),\n",
    "                              dataframe8[\"Y\"].to_numpy(),\n",
    "                              dataframe9[\"Y\"].to_numpy()))\n",
    "\n",
    "radius = np.column_stack((dataframe1[\"ConfidenceRadius\"].to_numpy(), \n",
    "                          dataframe2[\"ConfidenceRadius\"].to_numpy(),\n",
    "                          dataframe3[\"ConfidenceRadius\"].to_numpy(),\n",
    "                          dataframe4[\"ConfidenceRadius\"].to_numpy(),\n",
    "                          dataframe5[\"ConfidenceRadius\"].to_numpy(),\n",
    "                          dataframe6[\"ConfidenceRadius\"].to_numpy(),\n",
    "                          dataframe7[\"ConfidenceRadius\"].to_numpy(),\n",
    "                          dataframe8[\"ConfidenceRadius\"].to_numpy(),\n",
    "                          dataframe9[\"ConfidenceRadius\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4773b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a small dataframe to store results\n",
    "column_names = [\"ID\", \"Date1\", \"Date2\", \"DistanceD\", \"intersect?\", \"MaxD\", \"MinD\", \"intersection_Area\", \"Ratio_MinA\", \"Ratio_MaxA\"]\n",
    "#results = pd.DataFrame(columns=column_names)\n",
    "tempCalc1 = {\"ID\": indices}\n",
    "results = pd.DataFrame(tempCalc1)\n",
    "temp_results = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd05515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going through each rock in each timestep\n",
    "for j in range(len(dates)-1):\n",
    "    for i in range(len(indices)):\n",
    "        index = indices[i]\n",
    "        loc1 = np.array([location_x[i,j], location_y[i,j]])\n",
    "        loc2 = np.array([location_x[i,j+1], location_y[i,j+1]])\n",
    "        rad1 = radius[i,j]\n",
    "        rad2 = radius[i,j+1]\n",
    "        # Calculating displacement\n",
    "        distance, intersect, maxD, minD, intersection_area, ratio_minA, ratio_maxA = get_rock_displacement(loc1, loc2, rad1, rad2)\n",
    "        # Storing results\n",
    "        temp_results.loc[i] = [index, dates[j], dates[j+1], distance, intersect, maxD, minD, intersection_area, ratio_minA, ratio_maxA]\n",
    "    results = pd.concat([results, temp_results], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57788f3",
   "metadata": {},
   "source": [
    "### Sort by particle size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f787994",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv(\"../data/particleID_sizes.csv\")\n",
    "# make sure IDs are int\n",
    "sizes[\"particleID\"] = sizes[\"particleID\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Date1', 'Date2', 'DistanceD', 'intersect?', 'MaxD', 'MinD',\n",
       "       'intersection_Area', 'Ratio_MinA', 'Ratio_MaxA', 'Date1', 'Date2',\n",
       "       'DistanceD', 'intersect?', 'MaxD', 'MinD', 'intersection_Area',\n",
       "       'Ratio_MinA', 'Ratio_MaxA', 'Date1', 'Date2', 'DistanceD', 'intersect?',\n",
       "       'MaxD', 'MinD', 'intersection_Area', 'Ratio_MinA', 'Ratio_MaxA',\n",
       "       'Date1', 'Date2', 'DistanceD', 'intersect?', 'MaxD', 'MinD',\n",
       "       'intersection_Area', 'Ratio_MinA', 'Ratio_MaxA', 'Date1', 'Date2',\n",
       "       'DistanceD', 'intersect?', 'MaxD', 'MinD', 'intersection_Area',\n",
       "       'Ratio_MinA', 'Ratio_MaxA', 'Date1', 'Date2', 'DistanceD', 'intersect?',\n",
       "       'MaxD', 'MinD', 'intersection_Area', 'Ratio_MinA', 'Ratio_MaxA',\n",
       "       'Date1', 'Date2', 'DistanceD', 'intersect?', 'MaxD', 'MinD',\n",
       "       'intersection_Area', 'Ratio_MinA', 'Ratio_MaxA', 'Date1', 'Date2',\n",
       "       'DistanceD', 'intersect?', 'MaxD', 'MinD', 'intersection_Area',\n",
       "       'Ratio_MinA', 'Ratio_MaxA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the first ID column, keep all other columns\n",
    "id_positions = [i for i, c in enumerate(results.columns) if c == \"ID\"]\n",
    "keep_cols = [0] + [i for i in range(1, len(results.columns)) if i not in id_positions[1:]]\n",
    "results = results.iloc[:, keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bde63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on particle ID\n",
    "results[\"ID\"] = results[\"ID\"].astype(int)\n",
    "merged = results.merge(sizes, left_on=\"ID\", right_on=\"particleID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f2fc458",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'displacement_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# saving results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisplacement_results.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\tracers\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\tracers\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\tracers\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\tracers\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicol\\anaconda3\\envs\\tracers\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'displacement_results.csv'"
     ]
    }
   ],
   "source": [
    "# saving results\n",
    "results.to_csv(\"displacement_results.csv\", index=False, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53221e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
