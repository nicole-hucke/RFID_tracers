{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c1d9af",
   "metadata": {},
   "source": [
    "### Movement criteria for each particle displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceefb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries and determine functions\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_events_long(df):\n",
    "    \"\"\"\n",
    "    Reshape wide particle displacement data into long format.\n",
    "    Handles multiple events with .1, .2, ... suffixes.\n",
    "    \"\"\"\n",
    "    base_cols = [\"particleID\", \"gravelometer_size\"]\n",
    "    \n",
    "    # Find all Date1 columns (event starts)\n",
    "    date1_cols = [c for c in df.columns if c.startswith(\"Date1\")]\n",
    "    \n",
    "    long_rows = []\n",
    "    \n",
    "    for i, date1_col in enumerate(date1_cols):\n",
    "        # Columns for this event block\n",
    "        # Date1, Date2, DistanceD, intersect?, MaxD, MinD, Radius1, Radius2\n",
    "        suffix = \"\" if i == 0 else f\".{i}\"\n",
    "        cols = [\n",
    "            f\"Date1{suffix}\",\n",
    "            f\"Date2{suffix}\",\n",
    "            f\"DistanceD{suffix}\",\n",
    "            f\"intersect?{suffix}\",\n",
    "            f\"intersection_area{suffix}\",\n",
    "            f\"MaxD{suffix}\",\n",
    "            f\"MinD{suffix}\",\n",
    "            f\"Radius1{suffix}\",\n",
    "            f\"Radius2{suffix}\",\n",
    "        ]\n",
    "        \n",
    "        temp = df[base_cols + cols].copy()\n",
    "        # Rename to standard names\n",
    "        temp.columns = base_cols + [\"Date1\", \"Date2\", \"DistanceD\", \"intersect\", \"intersect_area\", \"MaxD\", \"MinD\", \"Radius1\", \"Radius2\"]\n",
    "        # Add event label\n",
    "        temp[\"event\"] = f\"M{i+1}\"\n",
    "        \n",
    "        long_rows.append(temp)\n",
    "    \n",
    "    # Combine all events\n",
    "    long_df = pd.concat(long_rows, ignore_index=True)\n",
    "    return long_df\n",
    "\n",
    "def valid_measurements(df):\n",
    "    \"\"\"\n",
    "    Determine valid measurements and movements based on criteria.\n",
    "    A measurement is valid if:\n",
    "        - distance > Radius1\n",
    "        - distance > Radius2\n",
    "\n",
    "    We compute this separately for:\n",
    "        - Euclidean Distance (DistanceD)\n",
    "        - Minimum Distance (MinD)\n",
    "        - Maximum Distance (MaxD)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # euclidean distance validity\n",
    "    df[\"valid_euc\"] = ((df[\"DistanceD\"] > df[\"Radius1\"]) & (df[\"DistanceD\"] > df[\"Radius2\"]))\n",
    "    # minimum distance validity\n",
    "    df[\"valid_min\"] = ((df[\"MinD\"] > df[\"Radius1\"]) & (df[\"MinD\"] > df[\"Radius2\"]))\n",
    "    # maximum distance validity\n",
    "    df[\"valid_max\"] = ((df[\"MaxD\"] > df[\"Radius1\"]) & (df[\"MaxD\"] > df[\"Radius2\"]))\n",
    "    return df\n",
    "\n",
    "def define_movement(df, valid_col):\n",
    "    \"\"\"\n",
    "    defines movement if a measurement is valid and that the distance > particle diameter \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    moved_col = valid_col.replace(\"valid\", \"moved\") # define moved column name\n",
    "    df[moved_col] = False # initialize moved column with False\n",
    "\n",
    "    for idx in df.index:\n",
    "        if not df.at[idx, valid_col]: # skip if measurement is not valid\n",
    "            continue\n",
    "\n",
    "        D = df.at[idx, \"DistanceD\"] # get distance\n",
    "        dia = df.at[idx, \"gravelometer_size\"] # get particle diameter\n",
    "\n",
    "        if D > dia/1000: # check if distance > diameter (converted to meters)\n",
    "            df.at[idx, moved_col] = True # mark as moved\n",
    "    return df\n",
    "\n",
    "def apply_counting_with_history(df, moved_col):\n",
    "    \"\"\"\n",
    "    - first TRUE movement is NOT counted\n",
    "    - second+ TRUE movements ARE counted\n",
    "    - if particle disappears the \"memory\" is reset \n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    counted_col = f\"counted_{moved_col}\"\n",
    "    df[counted_col] = False\n",
    "\n",
    "    df = df.sort_values([\"particleID\", \"event\"])\n",
    "\n",
    "    for pid in df[\"particleID\"].unique():\n",
    "        sub = df[df[\"particleID\"] == pid]\n",
    "\n",
    "        has_moved_before = False  # memory of previous movement\n",
    "\n",
    "        for idx in sub.index:\n",
    "            present = not pd.isna(df.at[idx, \"DistanceD\"])\n",
    "            moved_now = df.at[idx, moved_col]\n",
    "\n",
    "            # particle not present, reset memory\n",
    "            if not present:\n",
    "                has_moved_before = False\n",
    "                continue\n",
    "\n",
    "            # true movement\n",
    "            if moved_now:\n",
    "                if has_moved_before:\n",
    "                    # counted movement\n",
    "                    df.at[idx, counted_col] = True\n",
    "                else:\n",
    "                    # first movement (ignored)\n",
    "                    has_moved_before = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf1a05",
   "metadata": {},
   "source": [
    "Load and reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee100a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   particleID  gravelometer_size       Date1       Date2  DistanceD intersect  \\\n",
      "0           1              128.0  03_28_2022  07_06_2022   0.223329     False   \n",
      "1           1              128.0  07_06_2022  08_06_2022   0.086301     False   \n",
      "2           1              128.0  08_06_2022  08_09_2022   0.027935     False   \n",
      "3           1              128.0  08_09_2022    08_24_22   0.053109     False   \n",
      "4           1              128.0    08_24_22  03_24_2023   0.128443     False   \n",
      "\n",
      "   intersect_area      MaxD      MinD   Radius1   Radius2 event  \n",
      "0             0.0  0.379837  0.066822  0.127602  0.028905    M1  \n",
      "1             0.0  0.164265  0.008337  0.028905  0.049058    M2  \n",
      "2             0.0  0.177992  0.000000  0.049058  0.100999    M3  \n",
      "3             0.0  0.361647  0.000000  0.100999  0.207539    M4  \n",
      "4             0.0  0.384113  0.000000  0.207539  0.048131    M5  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../particle_displacement/displacement_results2.csv')\n",
    "df = reshape_events_long(df) \n",
    "# Sort by particleID first, then by event number\n",
    "df[\"event_num\"] = df[\"event\"].str.replace(\"M\",\"\").astype(int)\n",
    "df = df.sort_values([\"particleID\", \"event_num\"]).drop(columns=\"event_num\").reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffe8fa",
   "metadata": {},
   "source": [
    "Valid measurement and determine movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4418d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   particleID  gravelometer_size       Date1       Date2  DistanceD intersect  \\\n",
      "0           1              128.0  03_28_2022  07_06_2022   0.223329     False   \n",
      "1           1              128.0  07_06_2022  08_06_2022   0.086301     False   \n",
      "2           1              128.0  08_06_2022  08_09_2022   0.027935     False   \n",
      "3           1              128.0  08_09_2022    08_24_22   0.053109     False   \n",
      "4           1              128.0    08_24_22  03_24_2023   0.128443     False   \n",
      "\n",
      "   intersect_area      MaxD      MinD   Radius1   Radius2 event  valid_euc  \\\n",
      "0             0.0  0.379837  0.066822  0.127602  0.028905    M1       True   \n",
      "1             0.0  0.164265  0.008337  0.028905  0.049058    M2       True   \n",
      "2             0.0  0.177992  0.000000  0.049058  0.100999    M3      False   \n",
      "3             0.0  0.361647  0.000000  0.100999  0.207539    M4      False   \n",
      "4             0.0  0.384113  0.000000  0.207539  0.048131    M5      False   \n",
      "\n",
      "   valid_min  valid_max  \n",
      "0      False       True  \n",
      "1      False       True  \n",
      "2      False       True  \n",
      "3      False       True  \n",
      "4      False       True  \n"
     ]
    }
   ],
   "source": [
    "df = valid_measurements(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae8153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = define_movement(df, \"valid_euc\")\n",
    "df = define_movement(df, \"valid_min\")\n",
    "df = define_movement(df, \"valid_max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0466beb",
   "metadata": {},
   "source": [
    "Counting particle movement (with particle continuity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776ebf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_counting_with_history(df, \"moved_euc\")\n",
    "df = apply_counting_with_history(df, \"moved_min\")  \n",
    "df = apply_counting_with_history(df, \"moved_max\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727088bc",
   "metadata": {},
   "source": [
    "Movement Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68c95d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_particle_movement(df, moved_cols=[\"moved_min\",\"moved_euc\",\"moved_max\"]):\n",
    "    \"\"\"\n",
    "    summarizes particle movements per event and gravelometer size.\n",
    "    Counts total surveyed as all particles present (DistanceD not NaN),\n",
    "    excluding particles experiencing their first movement and invalid measurements.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    sizes = sorted(df[\"gravelometer_size\"].unique())\n",
    "    summary_rows = []\n",
    "\n",
    "    for event in sorted(df[\"event\"].unique(), key=lambda x: int(x.replace(\"M\",\"\"))):\n",
    "        sub = df[df[\"event\"] == event]\n",
    "\n",
    "        # Calculate eligible particles separately for each distance metric\n",
    "        for moved_col in moved_cols:\n",
    "            # Get corresponding validity column\n",
    "            valid_col = moved_col.replace(\"moved\", \"valid\")\n",
    "            counted_col = f\"counted_{moved_col}\"\n",
    "            \n",
    "            # Create exclusion mask specific to this distance metric\n",
    "            exclude_mask = pd.Series(False, index=sub.index)\n",
    "            \n",
    "            # Exclude if this specific metric had first movement (moved but not counted)\n",
    "            if counted_col in sub.columns:\n",
    "                first_movement_mask = (sub[moved_col] == True) & (sub[counted_col] == False)\n",
    "                exclude_mask = exclude_mask | first_movement_mask\n",
    "            \n",
    "            # Exclude if this specific metric is invalid\n",
    "            if valid_col in sub.columns:\n",
    "                invalid_mask = sub[valid_col] == False\n",
    "                exclude_mask = exclude_mask | invalid_mask\n",
    "            \n",
    "            # Count eligible particles for this specific distance metric\n",
    "            eligible_particles = sub[~sub[\"DistanceD\"].isna() & ~exclude_mask]\n",
    "            \n",
    "            # Total surveyed for this metric\n",
    "            total_surveyed = eligible_particles.groupby(\"gravelometer_size\")[\"particleID\"].nunique().reindex(sizes, fill_value=0)\n",
    "            total_surveyed[\"Total\"] = total_surveyed.sum()\n",
    "            summary_rows.append({\"event\": event, \"metric\": f\"Total surveyed, {moved_col}\", **total_surveyed.to_dict()})\n",
    "            \n",
    "            # Count moved particles for this metric\n",
    "            moved_counts = eligible_particles.groupby(\"gravelometer_size\")[moved_col].sum().reindex(sizes, fill_value=0)\n",
    "            moved_counts[\"Total\"] = moved_counts.sum()\n",
    "            summary_rows.append({\"event\": event, \"metric\": f\"Rocks moved, {moved_col}\", **moved_counts.to_dict()})\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df = summary_df[[\"event\", \"metric\"] + sizes + [\"Total\"]]\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9860373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event                     metric  11.0  16.0  22.6  32.0  45.0  64.0  90.0  \\\n",
      "0     M1  Total surveyed, moved_min     0     0     0     0     0     0     0   \n",
      "1     M1     Rocks moved, moved_min     0     0     0     0     0     0     0   \n",
      "2     M1  Total surveyed, moved_euc     0     0     0     0     0     1     1   \n",
      "3     M1     Rocks moved, moved_euc     0     0     0     0     0     0     0   \n",
      "4     M1  Total surveyed, moved_max     0     0     0     1     3     5     2   \n",
      "5     M1     Rocks moved, moved_max     0     0     0     0     0     0     0   \n",
      "6     M2  Total surveyed, moved_min     0     0     0     0     1     1     0   \n",
      "7     M2     Rocks moved, moved_min     0     0     0     0     1     0     0   \n",
      "8     M2  Total surveyed, moved_euc     0     1     1     3     4     3     1   \n",
      "9     M2     Rocks moved, moved_euc     0     1     1     3     4     2     1   \n",
      "10    M2  Total surveyed, moved_max     0     2     5    12    11    11     3   \n",
      "11    M2     Rocks moved, moved_max     0     2     5    12    10     7     3   \n",
      "12    M3  Total surveyed, moved_min     0     0     1     2     0     3     0   \n",
      "13    M3     Rocks moved, moved_min     0     0     1     2     0     3     0   \n",
      "14    M3  Total surveyed, moved_euc     0     1     1     4     4     6     2   \n",
      "15    M3     Rocks moved, moved_euc     0     1     1     4     1     6     1   \n",
      "16    M3  Total surveyed, moved_max     0     3     5    12    15    13     4   \n",
      "17    M3     Rocks moved, moved_max     0     2     5    10     5     6     1   \n",
      "18    M4  Total surveyed, moved_min     0     0     0     1     1     0     0   \n",
      "19    M4     Rocks moved, moved_min     0     0     0     1     1     0     0   \n",
      "20    M4  Total surveyed, moved_euc     0     1     1     5     3     4     2   \n",
      "21    M4     Rocks moved, moved_euc     0     1     1     5     3     4     0   \n",
      "22    M4  Total surveyed, moved_max     0     2     5    13    16    13     5   \n",
      "23    M4     Rocks moved, moved_max     0     2     3     8     9     7     1   \n",
      "24    M5  Total surveyed, moved_min     0     0     1     2     2     4     0   \n",
      "25    M5     Rocks moved, moved_min     0     0     1     2     2     4     0   \n",
      "26    M5  Total surveyed, moved_euc     0     0     2     2    10     7     1   \n",
      "27    M5     Rocks moved, moved_euc     0     0     2     2     9     7     1   \n",
      "28    M5  Total surveyed, moved_max     0     1     4     8    15    12     3   \n",
      "29    M5     Rocks moved, moved_max     0     1     4     6    11     7     1   \n",
      "30    M6  Total surveyed, moved_min     0     0     0     1     2     4     0   \n",
      "31    M6     Rocks moved, moved_min     0     0     0     1     2     4     0   \n",
      "32    M6  Total surveyed, moved_euc     0     0     0     2     4     6     0   \n",
      "33    M6     Rocks moved, moved_euc     0     0     0     2     4     6     0   \n",
      "34    M6  Total surveyed, moved_max     0     0     1     2     5     9     2   \n",
      "35    M6     Rocks moved, moved_max     0     0     1     2     5     7     1   \n",
      "36    M7  Total surveyed, moved_min     0     0     0     1     1     3     0   \n",
      "37    M7     Rocks moved, moved_min     0     0     0     1     1     1     0   \n",
      "38    M7  Total surveyed, moved_euc     0     0     0     4     5     5     2   \n",
      "39    M7     Rocks moved, moved_euc     0     0     0     3     4     3     0   \n",
      "40    M7  Total surveyed, moved_max     0     0     0    12    14    18    10   \n",
      "41    M7     Rocks moved, moved_max     0     0     0     6     7     9     0   \n",
      "42    M8  Total surveyed, moved_min     0     1     0     1     0     2     0   \n",
      "43    M8     Rocks moved, moved_min     0     1     0     1     0     1     0   \n",
      "44    M8  Total surveyed, moved_euc     0     1     2     7     4     3     3   \n",
      "45    M8     Rocks moved, moved_euc     0     1     2     7     4     2     0   \n",
      "46    M8  Total surveyed, moved_max     0     2     3    17    16    17    10   \n",
      "47    M8     Rocks moved, moved_max     0     2     3    13    12     9     2   \n",
      "\n",
      "    128.0  Total  \n",
      "0       0      0  \n",
      "1       0      0  \n",
      "2       1      3  \n",
      "3       0      0  \n",
      "4       2     13  \n",
      "5       0      0  \n",
      "6       0      2  \n",
      "7       0      1  \n",
      "8       1     14  \n",
      "9       0     12  \n",
      "10      2     46  \n",
      "11      0     39  \n",
      "12      1      7  \n",
      "13      1      7  \n",
      "14      1     19  \n",
      "15      1     15  \n",
      "16      4     56  \n",
      "17      2     31  \n",
      "18      0      2  \n",
      "19      0      2  \n",
      "20      0     16  \n",
      "21      0     14  \n",
      "22      4     58  \n",
      "23      0     30  \n",
      "24      1     10  \n",
      "25      1     10  \n",
      "26      1     23  \n",
      "27      1     22  \n",
      "28      3     46  \n",
      "29      2     32  \n",
      "30      1      8  \n",
      "31      1      8  \n",
      "32      1     13  \n",
      "33      1     13  \n",
      "34      3     22  \n",
      "35      3     19  \n",
      "36      0      5  \n",
      "37      0      3  \n",
      "38      2     18  \n",
      "39      0     10  \n",
      "40      7     61  \n",
      "41      2     24  \n",
      "42      1      5  \n",
      "43      0      3  \n",
      "44      2     22  \n",
      "45      1     17  \n",
      "46      6     71  \n",
      "47      2     43  \n"
     ]
    }
   ],
   "source": [
    "summary = summarize_particle_movement(df, moved_cols=[\"moved_min\", \"moved_euc\", \"moved_max\"])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c215e",
   "metadata": {},
   "source": [
    "Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9850a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('particle_movement_detailed.csv', index=False)\n",
    "summary.to_csv('particle_movement_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
